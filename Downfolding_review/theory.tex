\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}


\section{Downfolding as a compression of the energy functional}
\label{sec:theory}
\subsection{Theory} 
In this section, we will develop a sufficient criterion for an effective Hamiltonian $H_{eff}$ to reproduce the spectrum of a first-principles Hamiltonian $H$ within a chosen low-energy space. 
The criterion is that if a wave function $\ket{\Psi}$ is drawn from the low-energy space, then the expectation values of the effective and first principles Hamiltonian must match for that wave function.
We then use the concept of \textit{descriptors} to help parameterize the effective Hamiltonian in terms of expectation values on wave functions sampled from the low-energy space, such as hopping and two-body interaction terms. 
\subsubsection{Energy functional}
Suppose we start with a quantum system with Hamiltonian $H$ and Hilbert space ${\mathcal H}$.

\begin{definition}
Let the energy functional be $E[\Psi] = \frac{\bra{\Psi}H\ket{\Psi}}{\braket{\Psi|\Psi}}$ for a wavefunction $\ket{\Psi} \in {\mathcal H}$.
\end{definition}


\begin{theorem}
\label{theorem:criticalpoint}
$E[\Psi]$ has a critical point only where $\ket{\Psi}$ %\HJC{Should this be a ket, for consistencey with definition 1?} is an eigenstate of $H$.
\end{theorem}
\begin{proof}
\begin{eqnarray}
\frac{\delta }{\delta \Psi^*}  E[\Psi] = \frac{\delta}{\delta \Psi^*}\frac{\langle \Psi |H|\Psi\rangle}{\langle \Psi |\Psi\rangle} = \frac{H|\Psi\rangle}{\langle \Psi |\Psi\rangle} - \langle \Psi |H|\Psi\rangle \frac{|\Psi \rangle}{|\langle \Psi | \Psi\rangle|^2} =\frac{ (H-E[\Psi])|\Psi\rangle }{\langle\Psi|\Psi\rangle}\,.
\end{eqnarray}
Therefore, 
$\frac{\delta }{\delta \Psi^*}  E[\Psi] = 0$ if and only if $(H-E[\Psi])|\Psi\rangle =0$, i.e., $\Psi$ is an eigenvector of $H$ corresponding to eigenvalue $E[\Psi]$.  
\end{proof}

\subsubsection{Low energy space} 

\begin{definition}
Let $\mathcal{LE}(H,N)$ be a subset of ${\mathcal H}$ spanned by $N$ vectors given by the lowest energy solutions to $H\ket{\Psi_i}=E_i{\Psi_i}$. 
\end{definition}

\begin{definition}
$H_{eff}$ is an operator on the Hilbert space ${\mathcal {LE}(H,N)}$.	 
\end{definition}

\begin{definition}
The effective model $E_{eff}[\Psi]=\frac{\bra{\Psi}H_{eff}\ket{\Psi}}{\braket{\Psi|\Psi}}$ is a functional from $\mathcal{LE} \rightarrow \mathbb{R}$. 
\end{definition}

If $\ket{\Psi}\in \mathcal{LE}$ and $\ket{\Phi}\in {\mathcal H} \setminus \mathcal{LE}$, then $\ket{\Psi} \oplus \ket{\Phi} \in {\mathcal H}$.
In the following, we will use the direct sum operator $\oplus 0$ to translate between the larger ${\mathcal H}$ and the smaller $\mathcal{LE}$. 

\begin{lemma}
\label{lemma:zeroderiv}
Suppose that $\ket{\Psi}\in \mathcal{LE}$ and $\ket{\Phi} \in {\mathcal H} \setminus \mathcal{LE}$. 
Then $\left.\frac{\delta E[\Psi \oplus \Phi]}{\delta \Phi}\right|_{\Phi=0}=0$. 
\end{lemma}
\begin{proof}
$\langle \Psi\oplus 0 | H | 0\oplus \Phi \rangle=0$ because the two states have non-overlapping expansions in the eigenstates of $H$. 
Using that fact, we can evaluate
\begin{align}
\left.\frac{\delta E[\Psi \oplus \Phi]}{\delta \Phi}\right|_{\Phi=0} &= \left.\frac{\left(H-E[\Psi\oplus\Phi]\right) \ket{\Phi} }{\braket{\Psi|\Psi} + \braket{\Phi|\Phi}} \right|_{\Phi=0} = 0.
\end{align}
\end{proof}
This is equivalent to noting that $H$ is block diagonal in the partitioning of ${\mathcal H}$ into $\mathcal{LE}$ and ${\mathcal H} \setminus \mathcal{LE}$.
Importantly, if $\ket{\Psi} \in \mathcal{LE}$, then $\frac{\delta  E[\Psi\oplus 0] }{\delta (\Psi\oplus 0)^*} = \ket{\Psi'} \oplus 0$, where $\ket{\Psi'} \in \mathcal{LE} $. 

\begin{theorem}
\label{theorem:matching}
Assume $ E[\Psi\oplus 0]  = E_{eff}[\Psi]+C$ for any $\ket{\Psi } \in \mathcal{LE}$, where $C$ is a constant. 
Then $(H_{eff}+C)|\Psi\rangle\oplus 0 = H (|\Psi\rangle \oplus 0)$.
\end{theorem}
\begin{proof}
Note that
\begin{align}
	\frac{\delta E[\Psi\oplus 0]}{\delta (\Psi\oplus 0)^*}=\frac{(H-E[\Psi\oplus 0])\ket{\Psi\oplus 0} }{\braket{\Psi|\Psi}}
	\label{eqn:psider}
\end{align}
and 
\begin{align}
	\frac{\delta E_{eff}[\Psi]}{\delta \Psi^*}=\frac{(H_{eff}-E_{eff}[\Psi])\ket{\Psi} }{\braket{\Psi|\Psi}}.
	\label{eqn:psieffder}
\end{align}
Since the derivatives are equal, setting Eq.~\eqref{eqn:psider} equal to Eq.~\eqref{eqn:psieffder},
\begin{align}
	 H\ket{\Psi\oplus 0}= (H_{eff}+E[\Psi\oplus 0]-E_{eff}[\Psi])\ket{\Psi}\oplus 0 =(H_{eff}+C)\ket{\Psi}\oplus 0.
\end{align}
\end{proof}


Theorem~\ref{theorem:matching} combined with Lemma~\ref{lemma:zeroderiv} means that the eigenstates of $H_{eff}$ are be the same as the eigenstates of $H$ if its derivatives match $H$. 
Such $H_{eff}$ always exists. 
Let $H_{eff} = \sum_{i}^N E_i |\Psi_i\rangle \langle \Psi_i|$ where $|\Psi_i\rangle$'s are eigenstates belong to $\mathcal{LE}(H,N)$. This satisfies $E[\Psi] = E_{eff}[\Psi]$ and $H_{eff}|\Psi\rangle = H |\Psi \rangle$ for any $\Psi$ in $\mathcal{LE}(H,N)$.  

We have thus reduced the problem of finding an effective Hamiltonian $H_{eff}$ that reproduces the low-energy spectrum of $H$ to matching the corresponding energy functionals $E[\Psi]$ and $E_{eff}[\Psi]$. 
Practically, this can be implemented as follows: 
\begin{itemize}
\item [(1)]Generating an \textit{ansatz} for the effective Hamiltonian in terms of operators. 
\item [(2)]Generating wave functions $\ket{\Psi_i}$ in the low-energy subspace of the first principles Hilbert space ${\mathcal H}$.
\item [(3)]Computing $E[\Psi]$ using the expectation value of the first principles Hamiltonian and $E_{eff}[\Psi]$ by taking the expectation value of the operators in the ansatz for $H_{eff}$. 
\end{itemize}
%In this method, it is not necessary to diagonalize either of the Hamiltonians; one must only be able to select wave functions from the low-energy space $\mathcal{LE}$.
%\HJC{We repeat the above idea two lines later. I know it is important to say it, but it must be said once in such a short span}
We have thus reduced the problem of finding an effective Hamiltonian $H_{eff}$ that reproduces the low-energy spectrum of $H$ to matching the corresponding energy functionals $E[\Psi]$ and $E_{eff}[\Psi]$. 
This involves sampling the low-energy space, choosing the form of $H_{eff}$, and optimizing the parameters.
An important implication of this is that it is not necessary to diagonalize either of the Hamiltonians; one must only be able to select wave functions from the low-energy space $\mathcal{LE}$.
As we shall see, this can be substantially easier than attaining eigenstates.

Some further notes about this derivation:
\begin{itemize}
\item Fitting $\Psi$'s must come from $\mathcal{LE}$. It is not enough that the energy functional $E[\Psi]$ is less than some cutoff.\HJC{cutoff energy?}
\item In the case of sampling an approximate $\mathcal{LE}$, the error comes from non-parallelity of $E[\Psi]$ with the correct low energy manifold, up to a constant offset.
\item While $H_{eff}$ is unique, it has many potential representations and approximations. 
\item Our method can be applied to any manifold spanned by eigenstates
\item Model fitting is finding a compact approximation to $E_{eff}[\Psi]$. This is a high-dimensional space, so we use descriptors to do this.	
\item For operators that are not the Hamiltonian, it is possible to fit $\mathcal{O}_{eff}[\Psi] \simeq {\mathcal O}[\Psi]$ in a similar way. However, the eigenstates of ${\mathcal O}$ and ${\mathcal O}_{eff}$ will not coincide in general unless $\mathcal{O}$ commutes with the Hamiltonian.
\end{itemize}


The theory presented above maps coarse-graining into a functional approximation problem. 
This is still rather intimidating, since even supposing one can generate wave functions in the low-energy space, they are still complicated objects in a very large space.
An effective way to accomplish this is through the use of descriptors, $d_i[\Psi]$, which map from ${\mathcal H} \rightarrow \mathbb{R}$.
Then we can approximate the energy functional as follows
\begin{equation}
E_{eff}[\Psi] \simeq \sum_i f_i(d_i[\Psi]),
\end{equation}
where $f_i$ are some parameterized functions.
This will allow us to use techniques from statistical learning to efficiently describe $E_{eff}$. 
\subsection{Practical protocol}

\tikzstyle{decision} = [diamond, draw, fill=blue!10, 
    text width=4.5em, text badly centered, node distance=3cm, inner sep=0pt]
\tikzstyle{block} = [rectangle, draw, fill=blue!10, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{result} = [rectangle, draw, fill=red!10, 
    text width=5em, text centered, rounded corners, minimum height=4em]
\tikzstyle{line} = [draw,-latex',very thick]
\tikzstyle{cloud} = [draw, ellipse,fill=red!20, node distance=3cm,
    minimum height=2em]
\begin{figure*}[hbt]
\begin{tikzpicture}[scale=2,node distance = 3cm, auto]
    % Place nodes
    \node [block] (wfs) {Generate $\ket{\Psi_i} \in \mathcal{LE}$};
    \node [block, right of=wfs] (descriptors) {Generate $d_j[\Psi_i]$,$E[\Psi_i]$};
    \node [block, right of=descriptors] (assess) {Assess descriptors};
    \node [block, right of=assess] (ansatz) {Ansatz: $E_i \simeq \sum_j p_j d_{ij}$};
    \node [block, right of=ansatz] (fit) {Fit optimal model};
    \node [result, right of=fit] (model) {Effective model};
    % Draw edges
    \path [line] (wfs) -- (descriptors);
    \path [line] (descriptors) -- (assess);
    \path [line] (assess) --  (ansatz);
    \path [line] (ansatz) --  (fit);
    \path [line] (fit) --  (model);

    \path [line] (assess.south) -- ($ (assess.south) + (0,-0.2)$) 
                 -- node [below] {Incomplete sampling} 
                 ($ (wfs.south) + (0,-0.2)$) --  (wfs.south);
    \path [line] (assess.north) -- ($ (assess.north) + (0,0.2)$) 
                 -- node [above] {Incomplete descriptor space} 
                 ($ (descriptors.north) + (0,0.2)$) --  (descriptors.north);

\end{tikzpicture}
\caption{A practical protocol for fitting effective models to {\it ab initio} data.}
\label{fig:protocol} 
\end{figure*}

A practical protocol is presented in Figure~\ref{fig:protocol}. 
In this section we go through this procedure step by step.

\paragraph{Generating $\ket{\Psi_i}\in \mathcal{LE}$}
Ideally one would be able to sample the entire low-energy space. 
Typically, however, the space will be too large and it will need to be sampled. 
The optimal wave functions to use depend on the models one expects to fit, which we will discuss in detail  in later steps. 
Simple strategies that we will use in the examples below include excitations with respect to a determinant and varying spin states.


\paragraph{Generate $d_j[\Psi_i]$ and $E[\Psi_i]$} 
The choice of descriptor is fundamental to the success of the downfolding. 
In the case of a second-quantized Hamiltonian
\begin{equation}\label{eq:Heff_ansatz}
H_{eff} = E_0 + \sum_{ij} t_{ij} (c_i^\dagger c_j + h.c.) + \sum_{ijkl} V_{ijkl} c_i^\dagger c_j^\dagger c_k c_l,
\end{equation}
a set of linear descriptors by simply taking the expectation value of both sides of the equation. 
Then for example, the occupation descriptor for orbital $k$ is $d_{occ(k)}[\Psi_i] = \braket{\Psi_i | c_k^\dagger c_k | \Psi_i}$; the double occupation descriptor for orbital $k$ is $d_{double(k)}[\Psi_i] = \braket{\Psi_i | n_{k\uparrow}n_{k\downarrow} | \Psi_i}$. 
The orbital that $c_k$ represents is part of the descriptor, and in the examples below we will discuss this choice as well.
One is not limited to static orbital descriptors; they may have a more complex functional dependence on the trial function to include orbital relaxation.

 
\paragraph{Assess descriptors}
At this point, one has collected the data $E_i$ and $d_{ij}$. 
If two descriptors have a large correlation coefficient, then they are redundant in the data set. 
This could either mean that the sampling of the low-energy Hilbert space $\mathcal{LE}$ was insufficient, or that they are both proxies for the same differences in states. 
If two data points have the same or very similar descriptor sets, but different energies, then either the descriptor set is not enough to describe the variations in the low-energy space, or the sampling has generated states that are not in the low-energy space.
To resolve these possibilities, one should analyze the difference between the two wave functions.  

In either case, when the model is accurate, the fits will be accurate.
If descriptors values available in the reduced Hilbert space are not represented in the sampled wave functions, then intruder states can appear upon solution of the effective model. 
In that case, the model fitting is an extrapolation instead of an interpolation.
For this reason it is desirable to have eigenstates or near-eigenstates in the sample set if possible; they are guaranteed to be on the corners of the descriptor space if the model is accurate.


\paragraph{Ansatz: $E_i \simeq \sum_i  d_{ij} p_j$} 
If the descriptors are chosen well, then the model can be written in linear form:
\begin{equation}\label{eq:linearfit_descriptor}
E[\Psi_i] = \sum_j p_j d_j[\Psi_i],	
\end{equation}
which we shorten to 
\begin{equation}
{\bf E} = D{\bf p} .
\label{eqn:EdP}
\end{equation}
If this can be done, the fitting problem is reduced to a linear regression optimization.
More complex functions of the descriptors are also possible, although at the cost of making the effective model more difficult to solve and complicating the fitting procedure.


\paragraph{Fit optimal model}
Finally, one wishes to find a set of parameters such that Eq.~\eqref{eqn:EdP} is satisfied as closely as possible. 
For the example given in Eq~\eqref{eq:Heff_ansatz}, this would involve optimizing the parameters $E_0,t_{ij}, $ and $V_{ijkl}$. 
In terms of the generalized formalism in Eq~\eqref{eqn:EdP}, this involves optimizing the parameters ${\bf p}$. 
It is also possible to optimize the descriptors themselves, or to choose which descriptors to use among a set. 
In our tests, we have successfully used LASSO \cite{Lasso} and matching pursuit techniques \cite{MP_Zhang1993} to select high quality and compact model parameters. 
A detailed example of using the latter technique is presented in Section~\ref{subsection:fese}.


We would like to emphasize several advantages of our method: 
%\HJC{Some of the points below have been directly pasted from the response letter, but I would be careful about that. See example}
\begin{itemize}
\item [(1)] Our method provides an internal consistency check on the quality of the effective model in describing the corresponding \textit{ab initio} system. The quality of the linear fit tells the correctness of the model parameterization. 
\item [(2)] The low energy space is sampled by low energy states which do not have to be the eigenstates of the system. In other words, we do not need to exactly solve the \textit{ab initio} Hamiltonian or the model Hamiltonian, to know the map connecting the two Hamiltonians. The low energy non-eigenstates are computationally cheap to generate from first principles (e.g., quantum Monte Carlo method); 
%\HJC{We should not say this at all about possible superiority... this is OK for the letter not the manuscript}
\end{itemize}
The formulation of our method is exact in principle. However, in practical applications, there are mainly two approximations on (1) the form of the low energy Hamiltonian [Eq.~\eqref{eq:Heff_ansatz}]; (2) the low energy states we used to sample the low energy manifold. We assume that the low energy Hamiltonian could be written in terms of low energy degrees of freedom [$c_i$'s in Eq.~\eqref{eq:Heff_ansatz}] and we also only considered single-body and two-body terms. Nevertheless, the quality of the effective Hamiltonian is quantitatively measured by the quality of the linear regression fit. %\HJC{We use LASSO elsewhere, is our terminology consistent. LASSO=linear regression?}  % LASSO is a matching persuit method. 
